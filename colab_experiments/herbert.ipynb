{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/szdziedzic/intent-classification-for-polish-language/blob/main/colab_experiments/herbert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-b686QGsYf8j",
        "outputId": "2d4c688b-d613-4639-af29-0dfb755b6666"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.13.0-py3-none-any.whl (485 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.6/485.6 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.22.4)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Collecting dill<0.3.7,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.65.0)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.4.0)\n",
            "Collecting aiohttp (from datasets)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m67.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub<1.0.0,>=0.11.0 (from datasets)\n",
            "  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->datasets)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, multidict, frozenlist, dill, async-timeout, yarl, multiprocess, huggingface-hub, aiosignal, aiohttp, datasets\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 datasets-2.13.0 dill-0.3.6 frozenlist-1.3.3 huggingface-hub-0.15.1 multidict-6.0.4 multiprocess-0.70.14 xxhash-3.2.0 yarl-1.9.2\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttnWbJtSaH9c",
        "outputId": "33b5f63a-ace3-4e76-d739-e95341853095"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m94.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m104.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m83.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, safetensors, transformers\n",
            "Successfully installed safetensors-0.3.1 tokenizers-0.13.3 transformers-4.30.2\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrKWyc1LaiiN",
        "outputId": "490a3de6-1a45-42c2-ed2c-3079746aa734"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 kB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacremoses) (2022.10.31)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from sacremoses) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses) (1.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sacremoses) (4.65.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895241 sha256=e96ffe01819124f0d515f8015c4b0ce923b3bb08e4be376441ad1150edb6058f\n",
            "  Stored in directory: /root/.cache/pip/wheels/00/24/97/a2ea5324f36bc626e1ea0267f33db6aa80d157ee977e9e42fb\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses\n",
            "Successfully installed sacremoses-0.0.53\n"
          ]
        }
      ],
      "source": [
        "!pip install sacremoses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vR-1Tho1yqWN"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9-kjdd9YtbT",
        "outputId": "1976ff10-7870-45a6-b8c4-43f0a51bdee6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Found cached dataset massive (C:/Users/szdzi/.cache/huggingface/datasets/AmazonScience___massive/pl-PL/1.0.0/71d360eb7d7a18565ff8c10609cebf714fce3cc390e173ba5b02ffd48543cdc1)\n",
            "Found cached dataset massive (C:/Users/szdzi/.cache/huggingface/datasets/AmazonScience___massive/pl-PL/1.0.0/71d360eb7d7a18565ff8c10609cebf714fce3cc390e173ba5b02ffd48543cdc1)\n",
            "Found cached dataset massive (C:/Users/szdzi/.cache/huggingface/datasets/AmazonScience___massive/pl-PL/1.0.0/71d360eb7d7a18565ff8c10609cebf714fce3cc390e173ba5b02ffd48543cdc1)\n"
          ]
        }
      ],
      "source": [
        "MASSIVE_INTENTS = ['datetime_query', 'iot_hue_lightchange', 'transport_ticket', 'takeaway_query', 'qa_stock',\n",
        "            'general_greet', 'recommendation_events', 'music_dislikeness', 'iot_wemo_off', 'cooking_recipe',\n",
        "            'qa_currency', 'transport_traffic', 'general_quirky', 'weather_query', 'audio_volume_up',\n",
        "            'email_addcontact', 'takeaway_order', 'email_querycontact', 'iot_hue_lightup',\n",
        "            'recommendation_locations', 'play_audiobook', 'lists_createoradd', 'news_query',\n",
        "            'alarm_query', 'iot_wemo_on', 'general_joke', 'qa_definition', 'social_query',\n",
        "            'music_settings', 'audio_volume_other', 'calendar_remove', 'iot_hue_lightdim',\n",
        "            'calendar_query', 'email_sendemail', 'iot_cleaning', 'audio_volume_down',\n",
        "            'play_radio', 'cooking_query', 'datetime_convert', 'qa_maths', 'iot_hue_lightoff',\n",
        "            'iot_hue_lighton', 'transport_query', 'music_likeness', 'email_query', 'play_music',\n",
        "            'audio_volume_mute', 'social_post', 'alarm_set', 'qa_factoid', 'calendar_set',\n",
        "            'play_game', 'alarm_remove', 'lists_remove', 'transport_taxi', 'recommendation_movies',\n",
        "            'iot_coffee', 'music_query', 'play_podcasts', 'lists_query']\n",
        "\n",
        "train_dataset = load_dataset(\"AmazonScience/massive\", \"pl-PL\", split='train')\n",
        "val_dataset = load_dataset(\"AmazonScience/massive\", \"pl-PL\", split='validation')\n",
        "test_dataset = load_dataset(\"AmazonScience/massive\", \"pl-PL\", split='test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BHynYEfybly",
        "outputId": "fba60038-75a9-4595-9061-9a6e048a486a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'id': '1',\n",
              " 'locale': 'pl-PL',\n",
              " 'partition': 'train',\n",
              " 'scenario': 16,\n",
              " 'intent': 48,\n",
              " 'utt': 'obudź mnie o dziewiątej rano w piątek',\n",
              " 'annot_utt': 'obudź mnie o [time : dziewiątej rano] w [date : piątek]',\n",
              " 'worker_id': '9',\n",
              " 'slot_method': {'slot': ['time', 'date'],\n",
              "  'method': ['translation', 'translation']},\n",
              " 'judgments': {'worker_id': ['21', '11', '5'],\n",
              "  'intent_score': [1, 1, 1],\n",
              "  'slots_score': [1, 1, 1],\n",
              "  'grammar_score': [4, 4, 4],\n",
              "  'spelling_score': [2, 2, 2],\n",
              "  'language_identification': ['target', 'target', 'target']}}"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e40GjC3aWZpk",
        "outputId": "dcb721c8-d617-4468-d9cc-cc86e05e4014"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at allegro/herbert-base-cased were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.sso.sso_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.sso.sso_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "model_names = {\n",
        "    \"herbert-klej-cased-v1\": {\n",
        "        \"tokenizer\": \"allegro/herbert-klej-cased-tokenizer-v1\",\n",
        "        \"model\": \"allegro/herbert-klej-cased-v1\",\n",
        "    },\n",
        "    \"herbert-base-cased\": {\n",
        "        \"tokenizer\": \"allegro/herbert-base-cased\",\n",
        "        \"model\": \"allegro/herbert-base-cased\",\n",
        "    },\n",
        "    \"herbert-large-cased\": {\n",
        "        \"tokenizer\": \"allegro/herbert-large-cased\",\n",
        "        \"model\": \"allegro/herbert-large-cased\",\n",
        "    },\n",
        "}\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_names[\"herbert-base-cased\"][\"tokenizer\"])\n",
        "model = AutoModel.from_pretrained(model_names[\"herbert-base-cased\"][\"model\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "k8VcUceVkVfw"
      },
      "outputs": [],
      "source": [
        "class MASSIVEDataset(Dataset):\n",
        "    def __init__(self, dataset):\n",
        "        self.dataset = dataset\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        example = self.dataset[index]\n",
        "        return example[\"utt\"], example[\"intent\"]\n",
        "\n",
        "train_dataloader = DataLoader(Subset(MASSIVEDataset(train_dataset), range(100)), batch_size=32, shuffle=True)\n",
        "val_dataloader = DataLoader(Subset(MASSIVEDataset(val_dataset), range(50)), batch_size=32, shuffle=True)\n",
        "test_dataloader = DataLoader(Subset(MASSIVEDataset(test_dataset), range(50)), batch_size=32, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "wfF_S9WIlGhz"
      },
      "outputs": [],
      "source": [
        "class MASSIVEIntentClassifier(nn.Module):\n",
        "  def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(model.config.hidden_size, len(MASSIVE_INTENTS))\n",
        "\n",
        "  def forward(self, x):\n",
        "      x = self.linear(x)\n",
        "      return F.softmax(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ILgh1PWnzbT9"
      },
      "outputs": [],
      "source": [
        "def tokenize_batch(batch):\n",
        "    return tokenizer.batch_encode_plus(\n",
        "        batch,\n",
        "        padding=\"longest\",\n",
        "        add_special_tokens=True,\n",
        "        return_tensors=\"pt\",\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 667
        },
        "id": "j5w0cUkKmlTw",
        "outputId": "6ec06854-b38f-4748-f813-6a4a09474ca2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/50 [00:00<?, ?it/s]C:\\Users\\szdzi\\AppData\\Local\\Temp\\ipykernel_18260\\2599608986.py:8: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.softmax(x)\n",
            "#Epoch: 0, train loss: 16.38, train_acc: 0.00, val loss: 8.18, val_acc: 0.04:   2%|▏         | 1/50 [00:10<08:40, 10.63s/it]C:\\Users\\szdzi\\AppData\\Local\\Temp\\ipykernel_18260\\2599608986.py:8: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.softmax(x)\n",
            "#Epoch: 1, train loss: 16.35, train_acc: 0.06, val loss: 8.18, val_acc: 0.04:   4%|▍         | 2/50 [00:15<05:56,  7.42s/it]C:\\Users\\szdzi\\AppData\\Local\\Temp\\ipykernel_18260\\2599608986.py:8: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.softmax(x)\n",
            "#Epoch: 1, train loss: 16.35, train_acc: 0.06, val loss: 8.18, val_acc: 0.04:   4%|▍         | 2/50 [00:18<07:25,  9.28s/it]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[8], line 29\u001b[0m\n\u001b[0;32m     27\u001b[0m y_pred \u001b[39m=\u001b[39m intent_clf(pooler_output)\n\u001b[0;32m     28\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(y_pred, y_train)\n\u001b[1;32m---> 29\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     30\u001b[0m opt\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     31\u001b[0m train_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n",
            "File \u001b[1;32mc:\\Users\\szdzi\\miniconda3\\envs\\mldd23\\lib\\site-packages\\torch\\_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    389\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    390\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    394\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[0;32m    395\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[1;32m--> 396\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
            "File \u001b[1;32mc:\\Users\\szdzi\\miniconda3\\envs\\mldd23\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "number_of_epochs = 50\n",
        "\n",
        "intent_clf = MASSIVEIntentClassifier()\n",
        "intent_clf = intent_clf.cuda()\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "opt = torch.optim.Adam(\n",
        "  intent_clf.parameters(),\n",
        "  lr=3e-4,\n",
        ")\n",
        "epoch_progress = tqdm(list(range(number_of_epochs)))\n",
        "\n",
        "history = []\n",
        "for i in epoch_progress:\n",
        "    train_loss = 0\n",
        "    y_train_predicted = []\n",
        "    y_train_true = []\n",
        "    intent_clf.train()\n",
        "    for iteration, (X_train, y_train) in enumerate(train_dataloader):\n",
        "        y_train = y_train.cuda()\n",
        "        opt.zero_grad()\n",
        "        output = model(\n",
        "            **tokenize_batch(X_train)\n",
        "        )\n",
        "        pooler_output = output.pooler_output\n",
        "        pooler_output = pooler_output.cuda()\n",
        "        y_pred = intent_clf(pooler_output)\n",
        "        loss = loss_fn(y_pred, y_train)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        train_loss += loss.item()\n",
        "        y_train_predicted.extend(torch.argmax(y_pred, dim=-1).cpu().numpy())\n",
        "        y_train_true.extend(y_train.cpu().numpy())\n",
        "\n",
        "\n",
        "    val_loss = 0\n",
        "    y_predicted = []\n",
        "    y_true = []\n",
        "\n",
        "    intent_clf.eval()\n",
        "    with torch.no_grad():\n",
        "        for iteration, (X_val, y_val) in enumerate(val_dataloader):\n",
        "            y_val = y_val.cuda()\n",
        "            output = model(\n",
        "                **tokenize_batch(X_val)\n",
        "            )\n",
        "            pooler_output = output.pooler_output\n",
        "            pooler_output = pooler_output.cuda()\n",
        "            y_pred = intent_clf(pooler_output)\n",
        "            loss = loss_fn(y_pred, y_val)\n",
        "            val_loss += loss.item()\n",
        "            y_true.extend(y_val.cpu().numpy())\n",
        "            y_predicted.extend(torch.argmax(y_pred, dim=-1).cpu().numpy())\n",
        "    train_acc = accuracy_score(y_train_true, y_train_predicted)\n",
        "    val_acc = accuracy_score(y_true, y_predicted)\n",
        "    epoch_progress.set_description(f'#Epoch: {i}, train loss: {train_loss:.2f}, train_acc: {train_acc:.2f}, val loss: {val_loss:.2f}, val_acc: {val_acc:.2f}')\n",
        "    history.append({\"e\": i, \"train_acc\": train_acc, \"val_acc\": val_acc})"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyNUZQGRD+WQs1hwm2st9XGa",
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
